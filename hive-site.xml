<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>


 <!-- JDBC connect string for a JDBC metastore -->
 
  <!-- Auto creates necessary schema -->
  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>true</value>
    <description>Auto creates necessary schema</description>
  </property>

  <!-- Disable schema verification for the metastore -->
  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
    <description>Disable schema verification for the metastore</description>
  </property>
  
  <property>
  <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
  </property>

  <!-- Hive Server 2 Thrift Port -->
  <property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
    <description>Port number of HiveServer2 Thrift interface</description>
  </property>

  <!-- Hive Server 2 Authentication Mode -->
  <property>
    <name>hive.server2.authentication</name>
    <value>NOSASL</value>
    <description>Client authentication mode for HiveServer2</description>
  </property>

<property>
  <name>hive.server2.thrift.max.worker.threads</name>
  <value>100</value> <!-- Adjust the value based on your requirements -->
  <description>Maximum number of worker threads for HiveServer2 Thrift server.</description>
</property>




  <!-- Hive Server 2 Transport Mode -->
  <property>
    <name>hive.server2.transport.mode</name>
    <value>binary</value>
    <description>Thrift transport mode for HiveServer2</description>
  </property>

  <!-- Hostname or IP address for HiveServer2 to bind to -->
  <property>
    <name>hive.server2.thrift.bind.host</name>
    <value>localhost</value>
    <description>Hostname or IP address for HiveServer2 to bind to</description>
  </property>

<!-- count-->
<property>
  <name>hive.optimize.count.star</name>
  <value>true</value>
  <description>Optimize COUNT(*) queries</description>
</property>
<property>
  <name>hive.map.aggr</name>
  <value>true</value>
  <description>Use map-side aggregation for count queries</description>
</property>


<property>
  <name>hive.auto.convert.join.noconditionaltask.size</name>
  <value>1000000000</value>
  <description>Threshold for converting join to map join (bytes)</description>
</property>
<property>
  <name>hive.optimize.index.filter</name>
  <value>true</value>
  <description>Optimize index filters in query planning</description>
</property>
<property>
  <name>hive.vectorized.execution.enabled</name>
  <value>true</value>
  <description>Enable vectorized query execution for better performance</description>
</property>
   
   
   

























<property>
    <name>hive.server2.clear.dangling.scratchdir</name>
    <value>false</value>
    <description>Clear dangling scratch dir periodically in HS2</description>
  </property>
  <property>
    <name>hive.server2.clear.dangling.scratchdir.interval</name>
    <value>1800s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Interval to clear dangling scratch dir periodically in HS2
    </description>
  </property>
  <property>
    <name>hive.server2.sleep.interval.between.start.attempts</name>
    <value>60s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      The time should be in between 0 msec (inclusive) and 9223372036854775807 msec (inclusive).
      Amount of time to sleep between HiveServer2 start attempts. Primarily meant for tests
    </description>
  </property>
  <property>
    <name>hive.server2.max.start.attempts</name>
    <value>30</value>
    <description>
      Expects value bigger than 0.
      Number of times HiveServer2 will attempt to start before exiting. The sleep interval between retries is determined by hive.server2.sleep.interval.between.start.attempts
       The default of 30 will keep trying for 30 minutes.
    </description>
  </property>
  <property>
    <name>hive.server2.support.dynamic.service.discovery</name>
    <value>false</value>
    <description>Whether HiveServer2 supports dynamic service discovery for its clients. To support this, each instance of HiveServer2 currently uses ZooKeeper to register itself, when it is brought up. JDBC/ODBC clients should use the ZooKeeper ensemble: hive.zookeeper.quorum in their connection string.</description>
  </property>
  <property>
    <name>hive.server2.zookeeper.namespace</name>
    <value>hiveserver2</value>
    <description>The parent node in ZooKeeper used by HiveServer2 when supporting dynamic service discovery.</description>
  </property>
  <property>
    <name>hive.server2.zookeeper.publish.configs</name>
    <value>true</value>
    <description>Whether we should publish HiveServer2's configs to ZooKeeper.</description>
  </property>
  <property>
    <name>hive.server2.proxy.trustheader</name>
    <value/>
    <description>This config indicates whether the connection is authenticated before the requests lands on HiveServer2, So that we canavoid the authentication is again in HS2. Default value is empty, if it's value is set to some header say 'X-Trusted-Proxy-Auth-Header' then we need to look for this header in the connection string, if present we directly extract the client name from header.</description>
  </property>
  <property>
    <name>hive.server2.global.init.file.location</name>
    <value>${env:HIVE_CONF_DIR}</value>
    <description>
      Either the location of a HS2 global init file or a directory containing a .hiverc file. If the 
      property is set, the value must be a valid path to an init file or directory where the init file is located.
    </description>
  </property>
  <property>
    <name>hive.server2.transport.mode</name>
    <value>binary</value>
    <description>
      Expects one of [binary, http, all].
      Transport mode of HiveServer2.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.bind.host</name>
    <value/>
    <description>Bind host on which to run the HiveServer2 Thrift service.</description>
  </property>
  <property>
    <name>hive.driver.parallel.compilation</name>
    <value>false</value>
    <description>
      Whether to
      enable parallel compilation of the queries between sessions and within the same session on HiveServer2. The default is false.
    </description>
  </property>
  <property>
    <name>hive.driver.parallel.compilation.global.limit</name>
    <value>-1</value>
    <description>Determines the degree of parallelism for queries compilation between sessions on HiveServer2. The default is -1.</description>
  </property>
  <property>
    <name>hive.server2.compile.lock.timeout</name>
    <value>0s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Number of seconds a request will wait to acquire the compile lock before giving up. Setting it to 0s disables the timeout.
    </description>
  </property>
  <property>
    <name>hive.server2.parallel.ops.in.session</name>
    <value>true</value>
    <description>Whether to allow several parallel operations (such as SQL statements) in one session.</description>
  </property>
  <property>
    <name>hive.server2.materializedviews.registry.impl</name>
    <value>DEFAULT</value>
    <description>
      Expects one of [default, dummy].
      The implementation that we should use for the materialized views registry. 
        DEFAULT: Default cache for materialized views
        DUMMY: Do not cache materialized views and hence forward requests to metastore
    </description>
  </property>
  <property>
    <name>hive.server2.materializedviews.registry.refresh.period</name>
    <value>1500s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Period, specified in seconds, between successive refreshes of the registry to pull new materializations from the metastore that may have been created by other HS2 instances.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.host</name>
    <value>0.0.0.0</value>
    <description>The host address the HiveServer2 WebUI will listen on</description>
  </property>
  <property>
    <name>hive.server2.webui.port</name>
    <value>10002</value>
    <description>The port the HiveServer2 WebUI will listen on. This can beset to 0 or a negative integer to disable the web UI</description>
  </property>
  <property>
    <name>hive.server2.webui.max.threads</name>
    <value>50</value>
    <description>The max HiveServer2 WebUI threads</description>
  </property>
  <property>
    <name>hive.server2.webui.use.ssl</name>
    <value>false</value>
    <description>Set this to true for using SSL encryption for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.keystore.path</name>
    <value/>
    <description>SSL certificate keystore location for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.keystore.password</name>
    <value/>
    <description>SSL certificate keystore password for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.keystore.type</name>
    <value/>
    <description>SSL certificate keystore type for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.exclude.ciphersuites</name>
    <value/>
    <description>SSL a list of exclude cipher suite names or regular expressions separated by comma for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.keymanagerfactory.algorithm</name>
    <value/>
    <description>SSL certificate key manager factory algorithm for HiveServer2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.use.spnego</name>
    <value>false</value>
    <description>If true, the HiveServer2 WebUI will be secured with SPNEGO. Clients must authenticate with Kerberos.</description>
  </property>
  <property>
    <name>hive.server2.webui.spnego.keytab</name>
    <value/>
    <description>The path to the Kerberos Keytab file containing the HiveServer2 WebUI SPNEGO service principal.</description>
  </property>
  <property>
    <name>hive.server2.webui.spnego.principal</name>
    <value>HTTP/_HOST@EXAMPLE.COM</value>
    <description>
      The HiveServer2 WebUI SPNEGO service principal.
      The special string _HOST will be replaced automatically with 
      the value of hive.server2.webui.host or the correct host name.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.max.historic.queries</name>
    <value>25</value>
    <description>The maximum number of past queries to show in HiverSever2 WebUI.</description>
  </property>
  <property>
    <name>hive.server2.webui.use.pam</name>
    <value>false</value>
    <description>If true, the HiveServer2 WebUI will be secured with PAM.</description>
  </property>
  <property>
    <name>hive.server2.webui.explain.output</name>
    <value>false</value>
    <description>
      When set to true, the EXPLAIN output for every query is displayed in the HS2 WebUI / Drilldown / Query Plan tab.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.show.graph</name>
    <value>false</value>
    <description>Set this to true to to display query plan as a graph instead of text in the WebUI. Only works with hive.server2.webui.explain.output set to true.</description>
  </property>
  <property>
    <name>hive.server2.webui.max.graph.size</name>
    <value>25</value>
    <description>Max number of stages graph can display. If number of stages exceeds this, no queryplan will be shown. Only works when hive.server2.webui.show.graph and hive.server2.webui.explain.output set to true.</description>
  </property>
  <property>
    <name>hive.server2.webui.show.stats</name>
    <value>false</value>
    <description>Set this to true to to display statistics for MapReduce tasks in the WebUI. Only works when hive.server2.webui.show.graph and hive.server2.webui.explain.output set to true.</description>
  </property>
  <property>
    <name>hive.server2.webui.enable.cors</name>
    <value>false</value>
    <description>
      Whether to enable cross origin requests (CORS)
    </description>
  </property>
  <property>
    <name>hive.server2.webui.cors.allowed.origins</name>
    <value>*</value>
    <description>
      Comma separated list of origins that are allowed when CORS is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.cors.allowed.methods</name>
    <value>GET,POST,DELETE,HEAD</value>
    <description>
      Comma separated list of http methods that are allowed when CORS is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.cors.allowed.headers</name>
    <value>X-Requested-With,Content-Type,Accept,Origin</value>
    <description>
      Comma separated list of http headers that are allowed when CORS is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.xframe.enabled</name>
    <value>true</value>
    <description>
      Whether to enable xframe
    </description>
  </property>
  <property>
    <name>hive.server2.webui.xframe.value</name>
    <value>SAMEORIGIN</value>
    <description>
      Configuration to allow the user to set the x_frame-options value
    </description>
  </property>
  <property>
    <name>hive.server2.show.operation.drilldown.link</name>
    <value>false</value>
    <description>
      Whether to show the operation's drilldown link to thrift client.
    </description>
  </property>
  <property>
    <name>hive.server2.active.passive.ha.enable</name>
    <value>false</value>
    <description>Whether HiveServer2 Active/Passive High Availability be enabled when Hive Interactive sessions are enabled.This will also require hive.server2.support.dynamic.service.discovery to be enabled.</description>
  </property>
  <property>
    <name>hive.server2.active.passive.ha.registry.namespace</name>
    <value>hs2ActivePassiveHA</value>
    <description>
      When HiveServer2 Active/Passive High Availability is enabled, uses this namespace for registering HS2
      instances with zookeeper
    </description>
  </property>
  <property>
    <name>hive.server2.tez.interactive.queue</name>
    <value/>
    <description>
      A single YARN queues to use for Hive Interactive sessions. When this is specified,
      workload management is enabled and used for these sessions.
    </description>
  </property>
  <property>
    <name>hive.server2.wm.namespace</name>
    <value>default</value>
    <description>
      The WM namespace to use when one metastore is used by multiple compute clusters each 
      with their own workload management. The special value 'default' (the default) will 
      also include any resource plans created before the namespaces were introduced.
    </description>
  </property>
  <property>
    <name>hive.server2.wm.worker.threads</name>
    <value>4</value>
    <description>
      Number of worker threads to use to perform the synchronous operations with Tez
      sessions for workload management (e.g. opening, closing, etc.)
    </description>
  </property>
  <property>
    <name>hive.server2.wm.allow.any.pool.via.jdbc</name>
    <value>false</value>
    <description>
      Applies when a user specifies a target WM pool in the JDBC connection string. If
      false, the user can only specify a pool he is mapped to (e.g. make a choice among
      multiple group mappings); if true, the user can specify any existing pool.
    </description>
  </property>
  <property>
    <name>hive.server2.wm.pool.metrics</name>
    <value>true</value>
    <description>Whether per-pool WM metrics should be enabled.</description>
  </property>
  <property>
    <name>hive.server2.tez.wm.am.registry.timeout</name>
    <value>30s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      The timeout for AM registry registration, after which (on attempting to use the
      session), we kill it and try to get another one.
    </description>
  </property>
  <property>
    <name>hive.server2.wm.delayed.move</name>
    <value>false</value>
    <description>
      Determines behavior of the wm move trigger when destination pool is full.
      If true, the query will run in source pool as long as possible if destination pool is full;
      if false, the query will be killed if destination pool is full.
    </description>
  </property>
  <property>
    <name>hive.server2.wm.delayed.move.timeout</name>
    <value>3600</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      The amount of time a delayed move is allowed to run in the source pool,
      when a delayed move session times out, the session is moved to the destination pool.
      A value of 0 indicates no timeout
    </description>
  </property>
  <property>
    <name>hive.server2.wm.delayed.move.validator.interval</name>
    <value>60</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Interval for checking for expired delayed moves.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.default.queues</name>
    <value/>
    <description>
      A list of comma separated values corresponding to YARN queues of the same name.
      When HiveServer2 is launched in Tez mode, this configuration needs to be set
      for multiple Tez sessions to run in parallel on the cluster.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.sessions.per.default.queue</name>
    <value>1</value>
    <description>
      A positive integer that determines the number of Tez sessions that should be
      launched on each of the queues specified by "hive.server2.tez.default.queues".
      Determines the parallelism on each queue.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.initialize.default.sessions</name>
    <value>true</value>
    <description>
      This flag is used in HiveServer2 to enable a user to use HiveServer2 without
      turning on Tez for HiveServer2. The user could potentially want to run queries
      over Tez without the pool of sessions.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.queue.access.check</name>
    <value>false</value>
    <description>Whether to check user access to explicitly specified YARN queues. yarn.resourcemanager.webapp.address must be configured to use this.</description>
  </property>
  <property>
    <name>hive.server2.tez.session.lifetime</name>
    <value>162h</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is hour if not specified.
      The lifetime of the Tez sessions launched by HS2 when default sessions are enabled.
      Set to 0 to disable session expiration.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.session.lifetime.jitter</name>
    <value>3h</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is hour if not specified.
      The jitter for Tez session lifetime; prevents all the sessions from restarting at once.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.sessions.init.threads</name>
    <value>16</value>
    <description>
      If hive.server2.tez.initialize.default.sessions is enabled, the maximum number of
      threads to use to initialize the default sessions.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.sessions.restricted.configs</name>
    <value/>
    <description>
      The configuration settings that cannot be set when submitting jobs to HiveServer2. If
      any of these are set to values different from those in the server configuration, an
      exception will be thrown.
    </description>
  </property>
  <property>
    <name>hive.server2.tez.sessions.custom.queue.allowed</name>
    <value>true</value>
    <description>
      Expects one of [true, false, ignore].
      Whether Tez session pool should allow submitting queries to custom queues. The options
      are true, false (error out), ignore (accept the query but ignore the queue setting).
    </description>
  </property>
  <property>
    <name>hive.mapred.job.follow.tez.queue</name>
    <value>false</value>
    <description>Whether the MR jobs initiated by a query should be enforced to run in the queue denoted by 'tez.queue.name', e.g. DistCp jobs.</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.enabled</name>
    <value>true</value>
    <description>When true, HS2 will save operation logs and make them available for clients</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>${system:java.io.tmpdir}/${system:user.name}/operation_logs</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.level</name>
    <value>EXECUTION</value>
    <description>
      Expects one of [none, execution, performance, verbose].
      HS2 operation logging mode available to clients to be set at session level.
      For this to work, hive.server2.logging.operation.enabled should be set to true.
        NONE: Ignore any logging
        EXECUTION: Log completion of tasks
        PERFORMANCE: Execution + Performance logs 
        VERBOSE: All logs
    </description>
  </property>
  <property>
    <name>hive.server2.operation.log.cleanup.delay</name>
    <value>300s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      When a query is cancelled (via kill query, query timeout or triggers),
       operation logs gets cleaned up after this delay
    </description>
  </property>
  <property>
    <name>hive.server2.operation.log.purgePolicy.timeToLive</name>
    <value>60s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Number of seconds the appender, which has been dynamically created by Log4J framework for the operation log, should survive without having any events sent to it. For more details, check Log4J's IdlePurgePolicy.
    </description>
  </property>
  <property>
    <name>hive.server2.historic.operation.log.enabled</name>
    <value>false</value>
    <description>Keep the operation log for some time until the operation's query info is evicted from QueryInfoCache.</description>
  </property>
  <property>
    <name>hive.server2.historic.operation.log.check.interval</name>
    <value>15m</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      The time should be bigger than or equal to 3000 msec.
      The check interval for cleaning up the historic operation log and session dirs, which should be used only if hive.server2.historic.operation.log.enabled is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.operation.log.fetch.maxBytes</name>
    <value>4Mb</value>
    <description>
      Expects a byte size value with unit (blank for bytes, kb, mb, gb, tb, pb).
      The size should be in between 1 bytes (inclusive) and 2147483647 bytes (exclusive).
      The buffer size for fetching the operation log, which should be used only if hive.server2.historic.operation.log.enabled is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.limit.connections.per.user</name>
    <value>0</value>
    <description>Maximum hive server2 connections per user. Any user exceeding this limit will not be allowed to connect. Default=0 does not enforce limits.</description>
  </property>
  <property>
    <name>hive.server2.limit.connections.per.ipaddress</name>
    <value>0</value>
    <description>Maximum hive server2 connections per ipaddress. Any ipaddress exceeding this limit will not be allowed to connect. Default=0 does not enforce limits.</description>
  </property>
  <property>
    <name>hive.server2.limit.connections.per.user.ipaddress</name>
    <value>0</value>
    <description>Maximum hive server2 connections per user:ipaddress combination. Any user-ipaddress exceeding this limit will not be allowed to connect. Default=0 does not enforce limits.</description>
  </property>
  <property>
    <name>hive.server2.metrics.enabled</name>
    <value>false</value>
    <description>Enable metrics on the HiveServer2.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.port</name>
    <value>10001</value>
    <description>Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'http'.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.path</name>
    <value>cliservice</value>
    <description>Path component of URL endpoint when in HTTP mode.</description>
  </property>
  <property>
    <name>hive.server2.thrift.max.message.size</name>
    <value>104857600</value>
    <description>Maximum message size in bytes a HS2 server will accept.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.max.idle.time</name>
    <value>1800s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Maximum idle time for a connection on the server when in HTTP mode.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.http.worker.keepalive.time</name>
    <value>60s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Keepalive time for an idle http worker thread. When the number of workers exceeds min workers, excessive threads are killed after this time interval.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.http.request.header.size</name>
    <value>6144</value>
    <description>Request header size in bytes, when using HTTP transport mode. Jetty defaults used.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.response.header.size</name>
    <value>6144</value>
    <description>Response header size in bytes, when using HTTP transport mode. Jetty defaults used.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.compression.enabled</name>
    <value>true</value>
    <description>Enable thrift http compression via Jetty compression support</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.auth.enabled</name>
    <value>true</value>
    <description>When true, HiveServer2 in HTTP transport mode, will use cookie based authentication mechanism.</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.max.age</name>
    <value>86400s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Maximum age in seconds for server side cookie used by HS2 in HTTP mode.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.domain</name>
    <value/>
    <description>Domain for the HS2 generated cookies</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.path</name>
    <value/>
    <description>Path for the HS2 generated cookies</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.is.secure</name>
    <value>true</value>
    <description>Deprecated: Secure attribute of the HS2 generated cookie (this is automatically enabled for SSL enabled HiveServer2).</description>
  </property>
  <property>
    <name>hive.server2.thrift.http.cookie.is.httponly</name>
    <value>true</value>
    <description>HttpOnly attribute of the HS2 generated cookie.</description>
  </property>
  
  <property>
  <name>hive.server2.thrift.port</name>
  <value>10000</value>
</property>
<property>
  <name>hive.server2.thrift.bind.host</name>
  <value>localhost</value>
</property>

  <property>
    <name>hive.server2.thrift.sasl.qop</name>
    <value>auth</value>
    <description>
      Expects one of [auth, auth-int, auth-conf].
      Sasl QOP value; set it to one of following values to enable higher levels of
      protection for HiveServer2 communication with clients.
      Setting hadoop.rpc.protection to a higher level than HiveServer2 does not
      make sense in most situations. HiveServer2 ignores hadoop.rpc.protection in favor
      of hive.server2.thrift.sasl.qop.
        "auth" - authentication only (default)
        "auth-int" - authentication plus integrity protection
        "auth-conf" - authentication plus integrity and confidentiality protection
      This is applicable only if HiveServer2 is configured to use Kerberos authentication.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.min.worker.threads</name>
    <value>5</value>
    <description>Minimum number of Thrift worker threads</description>
  </property>
  <property>
    <name>hive.server2.thrift.max.worker.threads</name>
    <value>500</value>
    <description>Maximum number of Thrift worker threads</description>
  </property>
  <property>
    <name>hive.server2.thrift.worker.keepalive.time</name>
    <value>60s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Keepalive time (in seconds) for an idle worker thread. When the number of workers exceeds min workers, excessive threads are killed after this time interval.
    </description>
  </property>
  <property>
    <name>hive.server2.async.exec.threads</name>
    <value>100</value>
    <description>Number of threads in the async thread pool for HiveServer2</description>
  </property>
  <property>
    <name>hive.server2.async.exec.shutdown.timeout</name>
    <value>10s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      How long HiveServer2 shutdown will wait for async threads to terminate.
    </description>
  </property>
  <property>
    <name>hive.server2.async.exec.wait.queue.size</name>
    <value>100</value>
    <description>
      Size of the wait queue for async thread pool in HiveServer2.
      After hitting this limit, the async thread pool will reject new requests.
    </description>
  </property>
  <property>
    <name>hive.server2.async.exec.keepalive.time</name>
    <value>10s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Time that an idle HiveServer2 async thread (from the thread pool) will wait for a new task
      to arrive before terminating
    </description>
  </property>
  <property>
    <name>hive.server2.async.exec.async.compile</name>
    <value>false</value>
    <description>Whether to enable compiling async query asynchronously. If enabled, it is unknown if the query will have any resultset before compilation completed.</description>
  </property>
  <property>
    <name>hive.server2.long.polling.timeout</name>
    <value>5000ms</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Time that HiveServer2 will wait before responding to asynchronous calls that use long polling
    </description>
  </property>
  <property>
    <name>hive.session.impl.classname</name>
    <value/>
    <description>Classname for custom implementation of hive session</description>
  </property>
  <property>
    <name>hive.session.impl.withugi.classname</name>
    <value/>
    <description>Classname for custom implementation of hive session with UGI</description>
  </property>
  <property>
    <name>hive.server2.authentication</name>
    <value>NONE</value>
    <description>
      Expects one of [nosasl, none, ldap, kerberos, pam, custom, saml, jwt].
      Client authentication types.
        NONE: no authentication check
        LDAP: LDAP/AD based authentication
        KERBEROS: Kerberos/GSSAPI authentication
        CUSTOM: Custom authentication provider
                (Use with property hive.server2.custom.authentication.class)
        PAM: Pluggable authentication module
        NOSASL:  Raw transport
        SAML: SAML 2.0 compliant authentication. This is only supported in http transport mode.
        JWT: JWT based authentication. HS2 expects JWT contains the user name as subject and was signed by an
             asymmetric key. This is only supported in http transport mode.
    </description>
  </property>
  <property>
    <name>hive.server2.trusted.domain</name>
    <value/>
    <description>Specifies the host or a domain to trust connections from. Authentication is skipped for any connection coming from a host whose hostname ends with the value of this property. If authentication is expected to be skipped for connections from only a given host, fully qualified hostname of that host should be specified. By default it is empty, which means that all the connections to HiveServer2 are authenticated. When it is non-empty, the client has to provide a Hive user name. Any password, if provided, will not be used when authentication is skipped.</description>
  </property>
  <property>
    <name>hive.server2.trusted.domain.use.xff.header</name>
    <value>false</value>
    <description>When trusted domain authentication is enabled, the clients connecting to the HS2 could passthrough many layers of proxy. Some proxies append its own ip address to 'X-Forwarded-For' headerbefore passing on the request to another proxy or HS2. Some proxies also connect on behalf of clientand may create a separate connection to HS2 without binding using client IP. For such environments, insteadof looking at client IP from the request, if this config is set and if 'X-Forwarded-For' is present,trusted domain authentication will use left most ip address from X-Forwarded-For header.</description>
  </property>
  <property>
    <name>hive.server2.allow.user.substitution</name>
    <value>true</value>
    <description>Allow alternate user to be specified as part of HiveServer2 open connection request.</description>
  </property>
  <property>
    <name>hive.server2.authentication.kerberos.keytab</name>
    <value/>
    <description>Kerberos keytab file for server principal</description>
  </property>
  <property>
    <name>hive.server2.authentication.kerberos.principal</name>
    <value/>
    <description>Kerberos server principal</description>
  </property>
  <property>
    <name>hive.server2.authentication.client.kerberos.principal</name>
    <value/>
    <description>Kerberos principal used by the HA hive_server2s.</description>
  </property>
  <property>
    <name>hive.server2.authentication.spnego.keytab</name>
    <value/>
    <description>
      keytab file for SPNego principal, optional,
      typical value would look like /etc/security/keytabs/spnego.service.keytab,
      This keytab would be used by HiveServer2 when Kerberos security is enabled and 
      HTTP transport mode is used.
      This needs to be set only if SPNEGO is to be used in authentication.
      SPNego authentication would be honored only if valid
        hive.server2.authentication.spnego.principal
      and
        hive.server2.authentication.spnego.keytab
      are specified.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.spnego.principal</name>
    <value/>
    <description>
      SPNego service principal, optional,
      typical value would look like HTTP/_HOST@EXAMPLE.COM
      SPNego service principal would be used by HiveServer2 when Kerberos security is enabled
      and HTTP transport mode is used.
      This needs to be set only if SPNEGO is to be used in authentication.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.url</name>
    <value/>
    <description>
      LDAP connection URL(s),
      this value could contain URLs to multiple LDAP servers instances for HA,
      each LDAP URL is separated by a SPACE character. URLs are used in the 
       order specified until a connection is successful.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.baseDN</name>
    <value/>
    <description>LDAP base DN</description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.Domain</name>
    <value/>
    <description/>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupDNPattern</name>
    <value/>
    <description>
      COLON-separated list of patterns to use to find DNs for group entities in this directory.
      Use %s where the actual group name is to be substituted for.
      For example: CN=%s,CN=Groups,DC=subdomain,DC=domain,DC=com.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupFilter</name>
    <value/>
    <description>
      COMMA-separated list of LDAP Group names (short name not full DNs).
      For example: HiveAdmins,HadoopAdmins,Administrators
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.userDNPattern</name>
    <value/>
    <description>
      COLON-separated list of patterns to use to find DNs for users in this directory.
      Use %s where the actual group name is to be substituted for.
      For example: CN=%s,CN=Users,DC=subdomain,DC=domain,DC=com.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.userFilter</name>
    <value/>
    <description>
      COMMA-separated list of LDAP usernames (just short names, not full DNs).
      For example: hiveuser,impalauser,hiveadmin,hadoopadmin
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.guidKey</name>
    <value>uid</value>
    <description>
      LDAP attribute name whose values are unique in this LDAP server.
      For example: uid or CN.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupMembershipKey</name>
    <value>member</value>
    <description>
      LDAP attribute name on the group object that contains the list of distinguished names
      for the user, group, and contact objects that are members of the group.
      For example: member, uniqueMember or memberUid
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.userMembershipKey</name>
    <value/>
    <description>
      LDAP attribute name on the user object that contains groups of which the user is
      a direct member, except for the primary group, which is represented by the
      primaryGroupId.
      For example: memberOf
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupClassKey</name>
    <value>groupOfNames</value>
    <description>
      LDAP attribute name on the group entry that is to be used in LDAP group searches.
      For example: group, groupOfNames or groupOfUniqueNames.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.customLDAPQuery</name>
    <value/>
    <description>
      A full LDAP query that LDAP Atn provider uses to execute against LDAP Server.
      If this query returns a null resultset, the LDAP Provider fails the Authentication
      request, succeeds if the user is part of the resultset.For example: (&amp;(objectClass=group)(objectClass=top)(instanceType=4)(cn=Domain*)) 
      (&amp;(objectClass=person)(|(sAMAccountName=admin)(|(memberOf=CN=Domain Admins,CN=Users,DC=domain,DC=com)(memberOf=CN=Administrators,CN=Builtin,DC=domain,DC=com))))
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.userSearchFilter</name>
    <value/>
    <description>
      User search filter to be used with baseDN to search for users
      For example: (&amp;(uid={0})(objectClass=person))
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupBaseDN</name>
    <value/>
    <description>
      BaseDN for Group Search. This is used in conjunction with hive.server2.authentication.ldap.baseDN
      and 
      request, succeeds if the group is part of the resultset.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.groupSearchFilter</name>
    <value/>
    <description>
      Group search filter to be used with baseDN, userSearchFilter, groupBaseDN to search for users in groups
      For example: (&amp;(|(memberUid={0})(memberUid={1}))(objectClass=posixGroup))
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.binddn</name>
    <value/>
    <description>
      The user with which to bind to the LDAP server, and search for the full domain name of the user being authenticated.
      This should be the full domain name of the user, and should have search access across all users in the LDAP tree.
      If not specified, then the user being authenticated will be used as the bind user.
      For example: CN=bindUser,CN=Users,DC=subdomain,DC=domain,DC=com
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.ldap.bindpw</name>
    <value/>
    <description>
      The password for the bind user, to be used to search for the full name of the user being authenticated.
      If the username is specified, this parameter must also be specified.
    </description>
  </property>
  <property>
    <name>hive.server2.custom.authentication.class</name>
    <value/>
    <description>
      Custom authentication class. Used when property
      'hive.server2.authentication' is set to 'CUSTOM'. Provided class
      must be a proper implementation of the interface
      org.apache.hive.service.auth.PasswdAuthenticationProvider. HiveServer2
      will call its Authenticate(user, passed) method to authenticate requests.
      The implementation may optionally implement Hadoop's
      org.apache.hadoop.conf.Configurable class to grab Hive's Configuration object.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.pam.services</name>
    <value/>
    <description>
      List of the underlying pam services that should be used when auth type is PAM
      A file with the same name must exist in /etc/pam.d
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.jwt.jwks.url</name>
    <value/>
    <description>
      URL of the file from where URLBasedJWKSProvider will try to load JWKS if JWT is enabled for the
      authentication mode.
    </description>
  </property>
  <property>
    <name>hive.server2.authentication.jwt.jwks.skip.ssl.cert</name>
    <value>false</value>
    <description>
      When this is enabled, the SSL certificate verification will be skipped.
      This is meant to be used in a testing environment only. Do not use in production.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.keystore.path</name>
    <value/>
    <description>
      Keystore path to the saml2 client. This keystore is used to store the
       key pair used to sign the authentication requests when hive.server2.saml2.sign.requests
       is set to true. If the path doesn't exist, HiveServer2 will attempt to
       create a keystore using the default configurations otherwise it will use
       the one provided.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.keystore.password</name>
    <value/>
    <description>
      Password to the keystore used to sign the authentication requests. By default,
       this must be set to a non-blank value if the authentication mode is SAML.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.private.key.password</name>
    <value/>
    <description>
      Password for the private key which is stored in the keystore pointed 
       by hive.server2.saml2.keystore.path. This key is used to sign the authentication request
       if hive.server2.saml2.sign.requests is set to true.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.idp.metadata</name>
    <value/>
    <description>
      IDP metadata file for the SAML configuration. This metadata file must be
       exported from the external identity provider. This is used to validate the SAML assertions
       received by HiveServer2.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.sp.entity.id</name>
    <value/>
    <description>
      Service provider entity id for this HiveServer2. This must match with the
       SP id on the external identity provider. If this is not set, HiveServer2 will use the
       callback url as the SP id.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.sp.force.auth</name>
    <value>false</value>
    <description>
      This is a boolean configuration which toggles the force authentication
       flag in the SAML authentication request. When set to true, the request generated
       to the IDP will ask the IDP to force the authentication again.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.max.authentication.lifetime</name>
    <value>1h</value>
    <description>
      This configuration can be used to set the lifetime of the
       authentication response from IDP. Generally the IDP will not ask
       you enter credentials if you have a authenticated session with it already.
       The IDP will automatically generate an assertion in such a case. This configuration
       can be used to set the time limit for such assertions. Assertions which are
       older than this value will not be accepted by HiveServer2. The default
       is one hour.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.blacklisted.signature.algorithms</name>
    <value/>
    <description>
      Comma separated list of signature algorithm names which are not
       allowed by HiveServer2 during validation of the assertions received from IDP
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.acs.index</name>
    <value/>
    <description>
      This configuration specifies the assertion consumer service (ACS)
       index to be sent to the IDP in case it support multiple ACS URLs. This
       will also be used to pick the ACS URL from the IDP metadata for validation.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.sp.callback.url</name>
    <value/>
    <description>
      Callback URL where SAML responses should be posted. Currently this
       must be configured at the same port number as defined by hive.server2.thrift.http.port.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.want.assertions.signed</name>
    <value>true</value>
    <description>
      When this configuration is set to true, hive server2 will validate the signature
       of the assertions received at the callback url. For security reasons, it is recommendedthat this value should be true.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.sign.requests</name>
    <value>false</value>
    <description>
      When this configuration is set to true, HiveServer2 will sign the SAML requests
       which can be validated by the IDP provider.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.callback.token.ttl</name>
    <value>30s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Time for which the token issued by
      service provider is valid.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.group.attribute.name</name>
    <value/>
    <description>
      The attribute name in the SAML assertion which would
       be used to compare for the group name matching. By default it is empty
       which would allow any authenticated user. If this value is set then
       then hive.server2.saml2.group.filter must be set to a non-empty value.
    </description>
  </property>
  <property>
    <name>hive.server2.saml2.group.filter</name>
    <value/>
    <description>
      Comma separated list of group names which will be allowed when SAML
       authentication is enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>true</value>
    <description>
      Setting this property to true will have HiveServer2 execute
      Hive operations as the user making the calls to it.
    </description>
  </property>
  <property>
    <name>hive.server2.service.users</name>
    <value/>
    <description>Comma separated list of users to have HiveServer2 skip authorization when compiling queries.</description>
  </property>
  <property>
    <name>hive.distcp.privileged.doAs</name>
    <value>hive</value>
    <description>
      This property allows privileged distcp executions done by hive
      to run as this user.
    </description>
  </property>
  <property>
    <name>hive.server2.table.type.mapping</name>
    <value>CLASSIC</value>
    <description>
      Expects one of [classic, hive].
      This setting reflects how HiveServer2 will report the table types for JDBC and other
      client implementations that retrieve the available tables and supported table types
        HIVE : Exposes Hive's native table types like MANAGED_TABLE, EXTERNAL_TABLE, VIRTUAL_VIEW
        CLASSIC : More generic types like TABLE and VIEW
    </description>
  </property>
  <property>
    <name>hive.server2.session.hook</name>
    <value/>
    <description/>
  </property>
  <property>
    <name>hive.server2.use.SSL</name>
    <value>false</value>
    <description>Set this to true for using SSL encryption in HiveServer2.</description>
  </property>
  <property>
    <name>hive.server2.keystore.path</name>
    <value/>
    <description>SSL certificate keystore location.</description>
  </property>
  <property>
    <name>hive.server2.keystore.password</name>
    <value/>
    <description>SSL certificate keystore password.</description>
  </property>
  <property>
    <name>hive.server2.keystore.type</name>
    <value/>
    <description>SSL certificate keystore type.</description>
  </property>
  <property>
    <name>hive.server2.keymanagerfactory.algorithm</name>
    <value/>
    <description>SSL certificate keystore algorithm.</description>
  </property>
  <property>
    <name>hive.server2.http.exclude.ciphersuites</name>
    <value/>
    <description>SSL a list of exclude cipher suite names or regular expressions separated by comma for HiveServer2 http server.</description>
  </property>
  <property>
    <name>hive.server2.binary.include.ciphersuites</name>
    <value/>
    <description>SSL a list of include cipher suite names separated by colon for HiveServer2 binary Cli Server</description>
  </property>
  <property>
    <name>hive.server2.builtin.udf.whitelist</name>
    <value/>
    <description>
      Comma separated list of builtin udf names allowed in queries.
      An empty whitelist allows all builtin udfs to be executed.  The udf black list takes precedence over udf white list
    </description>
  </property>
  <property>
    <name>hive.server2.builtin.udf.blacklist</name>
    <value/>
    <description>Comma separated list of udfs names. These udfs will not be allowed in queries. The udf black list takes precedence over udf white list</description>
  </property>
  <property>
    <name>hive.allow.udf.load.on.demand</name>
    <value>false</value>
    <description>
      Whether enable loading UDFs from metastore on demand; this is mostly relevant for
      HS2 and was the default behavior before Hive 1.2. Off by default.
    </description>
  </property>
  <property>
    <name>hive.server2.session.check.interval</name>
    <value>15m</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      The time should be bigger than or equal to 3000 msec.
      The check interval for session/operation timeout, which can be disabled by setting to zero or negative value.
    </description>
  </property>
  <property>
    <name>hive.server2.close.session.on.disconnect</name>
    <value>true</value>
    <description>Session will be closed when connection is closed. Set this to false to have session outlive its parent connection.</description>
  </property>
  <property>
    <name>hive.server2.idle.session.timeout</name>
    <value>4h</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Session will be closed when it's not accessed for this duration, which can be disabled by setting to zero or negative value.
    </description>
  </property>
  <property>
    <name>hive.server2.idle.operation.timeout</name>
    <value>2h</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Operation will be closed when it's not accessed for this duration of time, which can be disabled by setting to zero value.
        With positive value, it's checked for operations in terminal state only (FINISHED, CANCELED, CLOSED, ERROR).
        With negative value, it's checked for all of the operations regardless of state.
    </description>
  </property>
  <property>
    <name>hive.server2.idle.session.check.operation</name>
    <value>true</value>
    <description>
      Session will be considered to be idle only if there is no activity, and there is no pending operation.
       This setting takes effect only if session idle timeout (hive.server2.idle.session.timeout) and checking
      (hive.server2.session.check.interval) are enabled.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.client.retry.limit</name>
    <value>1</value>
    <description>Number of retries upon failure of Thrift HiveServer2 calls</description>
  </property>
  <property>
    <name>hive.server2.thrift.client.connect.retry.limit</name>
    <value>1</value>
    <description>Number of retries while opening a connection to HiveServe2</description>
  </property>
  <property>
    <name>hive.server2.thrift.client.retry.delay.seconds</name>
    <value>1s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Number of seconds for the HiveServer2 thrift client to wait between consecutive connection attempts. Also specifies the time to wait between retrying thrift calls upon failures
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.client.user</name>
    <value>anonymous</value>
    <description>Username to use against thrift client</description>
  </property>
  <property>
    <name>hive.server2.thrift.client.password</name>
    <value>anonymous</value>
    <description>Password to use against thrift client</description>
  </property>
  <property>
    <name>hive.server2.thrift.resultset.serialize.in.tasks</name>
    <value>false</value>
    <description>
      Whether we should serialize the Thrift structures used in JDBC ResultSet RPC in task nodes.
       We use SequenceFile and ThriftJDBCBinarySerDe to read and write the final results if this is true.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.resultset.max.fetch.size</name>
    <value>10000</value>
    <description>Max number of rows sent in one Fetch RPC call by the server to the client.</description>
  </property>
  <property>
    <name>hive.server2.thrift.resultset.default.fetch.size</name>
    <value>1000</value>
    <description>
      The number of rows sent in one Fetch RPC call by the server to the client, if not
      specified by the client.
    </description>
  </property>
  <property>
    <name>hive.server2.xsrf.filter.enabled</name>
    <value>false</value>
    <description>If enabled, HiveServer2 will block any requests made to it over http if an X-XSRF-HEADER header is not present</description>
  </property>
  <property>
    <name>hive.server2.csrf.filter.enabled</name>
    <value>false</value>
    <description>If enabled, HiveServer2 will block any requests made to it over http if an X-CSRF-TOKEN header is not present</description>
  </property>
  <property>
    <name>hive.security.command.whitelist</name>
    <value>set,reset,dfs,add,list,delete,reload,compile,llap</value>
    <description>Comma separated list of non-SQL Hive commands users are authorized to execute</description>
  </property>
  <property>
    <name>hive.server2.job.credential.provider.path</name>
    <value/>
    <description>If set, this configuration property should provide a comma-separated list of URLs that indicates the type and location of providers to be used by hadoop credential provider API. It provides HiveServer2 the ability to provide job-specific credential providers for jobs run using Tez, MR execution engines.</description>
  </property>
  <property>
    <name>hive.server2.graceful.stop.timeout</name>
    <value>1800s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Maximum time waiting for live queries being finished and stopping HiveServer2. With value not greater than 30s(the overhead to stop HiveServer2), it will not wait for the live queries to be done, instead call stop directly to shutdown HiveServer2 gracefully
    </description>
    </property>
     
     
     
     <property>
  <name>hive.exec.dynamic.partition.mode</name>
  <value>nonstrict</value>
</property>

     <property>
  <name>hive.server2.metastore.uris</name>
  <value>thrift://localhost:9083</value>
</property>
<property>
  <name>hive.server2.execution.engine</name>
  <value>tez</value>
</property>
<property>
  <name>tez.lib.uris</name>
  <value>/opt/tez/*</value>
</property>

<property>
  <name>hive.server2.tez.container.size</name>
  <value>1024</value> <!-- Example: Set as per your cluster configuration -->
</property>

<!-- hive-site.xml -->


     
     
     <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:postgresql://127.0.0.1:5432/hive_metastore</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>

  <!-- Driver class name for a JDBC metastore -->
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.postgresql.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <!-- Username to use against metastore database -->
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hiveuser</value>
    <description>Username to use against metastore database</description>
  </property>

  <!-- Password to use against metastore database -->
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>nandhu01</value>
    <description>Password to use against metastore database</description>
  </property>

    
    <property>
  <name>hive.server2.enable.doAs</name>
  <value>true</value>
  <description>Enable impersonation in HiveServer2</description>
</property>


<property>
        <name>hadoop.proxyuser.nandhumidhun.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.nandhumidhun.hosts</name>
        <value>*</value>
    </property>

</configuration>

